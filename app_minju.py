import streamlit as st
import os
import openai as ai
from PyPDF2 import PdfReader

import os
import pymysql

from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.document_loaders import DirectoryLoader
from langchain.prompts import ChatPromptTemplate
from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate
from langchain.chat_models import ChatOpenAI


# ai.api_key = st.secrets["openai_key"]
ai.api_key = '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'

db_config = {
    'host': 'recruit.cob9hpevtink.ap-northeast-2.rds.amazonaws.com',
    'database': 'new_schema',
    'port': 3306,
    'user': 'admin',
    'password': '201912343'
}

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
db = pymysql.connect(**db_config)
cursor = db.cursor()

# í´ë” ê²½ë¡œ ìƒì„±
output_folder = 'txt_data'
os.makedirs(output_folder, exist_ok=True)

try:
    # ê³ ìœ í•œ corp_name ê°’ ê°€ì ¸ì˜¤ê¸°
    sql = 'SELECT DISTINCT corp_name FROM recuity'
    cursor.execute(sql)
    
    corp_names = cursor.fetchall()
    
    for corp_name in corp_names:
        # ê° corp_nameì— ëŒ€í•œ TXT íŒŒì¼ ê²½ë¡œ ìƒì„±
        txt_file_name = os.path.join(output_folder, f'{corp_name[0]}.txt')
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰ (í•´ë‹¹ corp_nameì„ ê°€ì§„ í–‰ì„ ê°€ì ¸ì˜´)
        sql = f'SELECT * FROM recuity WHERE corp_name = %s'
        cursor.execute(sql, (corp_name[0],))
        
        # ê²°ê³¼ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥
        with open(txt_file_name, 'w', encoding='utf-8') as txt_file:
            # Get the column names
            column_names = [desc[0] for desc in cursor.description]
            txt_file.write(', '.join(column_names) + '\n')
            
            result = cursor.fetchall()
            for row in result:
                # Write column names and corresponding data values
                for col_name, data in zip(column_names, row):
                    txt_file.write(f'{col_name}: {data}\n')
                txt_file.write('\n')  # ê° íšŒì‚¬ ë°ì´í„° êµ¬ë¶„ì„ ìœ„í•œ ì¤„ ë°”ê¿ˆ ì¶”ê°€

finally:
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë‹«ê¸°
    db.close()
    
loader = DirectoryLoader('./txt_data', glob='*.txt', loader_cls=TextLoader)
documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #1000ì ì”© ëŠë˜, 200ì ì”© ê²¹ì¹˜ê²Œ ë§Œë“ ë‹¤.
texts = text_splitter.split_documents(documents)

os.environ['OPENAI_API_KEY'] = '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'

persist_directory='db'

embedding = OpenAIEmbeddings()

vectordb = Chroma.from_documents(
    documents=texts,
    embedding=embedding,
    persist_directory=persist_directory
)
vectordb.persist() # ì´ˆê¸°í™”
vectordb=None

vectordb = Chroma( # ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ
    persist_directory=persist_directory,
    embedding_function=embedding
)

retriever = vectordb.as_retriever(search_kwargs={"k": 3}) # ìœ ì‚¬ë„ ìƒìœ„ 3ê°œë§Œ ë°˜í™˜

docs = retriever.get_relevant_documents("ì¬íƒê·¼ë¬´, ìœ ì—° ê·¼ë¬´ì œ")

source_list = []

for doc in docs:
    source = doc.metadata["source"]
    cleaned_source = source.replace("txt_data/", "").replace(".txt", "")
    source_list.append(cleaned_source)


text = ""

# source_listì— ìˆëŠ” ê° ê¸°ì—…ëª…ì— ëŒ€í•˜ì—¬
for source in source_list:
    # íŒŒì¼ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
    file_name = f"txt_data/{source}.txt"
    
    # íŒŒì¼ì„ ì½ê³  ë‚´ìš©ì„ text ë³€ìˆ˜ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    with open(file_name, 'r', encoding='utf-8') as f:
        text += f.read()

tab1, tab2= st.tabs(['íšŒì‚¬ ì°¾ê¸°', 'ìì†Œì„œ ì“°ê¸°'])

with tab1:
    st.markdown("""
    # ğŸ“ ë³¸ì¸ì´ ì›í•˜ëŠ” ìŠ¤íƒ€íŠ¸ì—…ì˜ ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”
    
    ì„±í–¥ì— ë§ëŠ” ìŠ¤íƒ€íŠ¸ì—…ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.
    """
    )
    
    options = st.multiselect(
    'ìì‹ ì˜ ì›í•˜ëŠ” ìŠ¤íƒ€íŠ¸ì—…ì˜ í•µì‹¬ê°€ì¹˜ë¥¼ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”',
    ['í¸í•œ ë³µì¥', 'ììœ ë¡œìš´ ì†Œí†µ', 'í›Œë¥­í•œ ë™ë£Œ', 'ì„±ì¥ ê°€ëŠ¥ì„±ì´ ìˆëŠ”', 'ì›Œë¼ë°¸ì´ ë³´ì¥ëœ', 'ììœ¨ì¬íƒê·¼ë¬´', 'íƒ„íƒ„í•œ ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸', 'ê°œë°œ ëŠ¥ë ¥ í–¥ìƒ'],
    default=['í¸í•œ ë³µì¥'])
    
    str_options = ', '.join(options)

    retriever = vectordb.as_retriever(search_kwargs={"k": 3})
    
    docs = retriever.get_relevant_documents(str_options)
    
    source_list = []

    for doc in docs:
        source = doc.metadata["source"]
        cleaned_source = source.replace("txt_data/", "").replace(".txt", "")
        source_list.append(cleaned_source)
        
    for i, source in enumerate(source_list):
        if st.button(source, key=f'button_{i}'):  # ê³ ìœ í•œ í‚¤ í• ë‹¹
            st.write(source)
        
    
with tab2: 
    st.markdown("""
    # ğŸ“ ìƒì„±í˜•AI ê¸°ë°˜ ìê¸°ì†Œê°œì„œ ìƒì„±ê¸°

    ìê¸°ì†Œê°œì„œë¥¼ ì œì‘í•˜ê¸° ìœ„í•œ ë‹¨ê³„:
    1. ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œ í•˜ê±°ë‚˜, í…ìŠ¤íŠ¸ë¡œ ë³µì‚¬/ë¶™ì—¬ë„£ê¸°ë¥¼ í•´ì£¼ì„¸ìš”
    2. ì§ë¬´ ì†Œê°œì„œë¥¼ ë³µì‚¬/ë¶™ì—¬ë„£ê¸° í•´ì£¼ì„¸ìš”
    3. ì§€ì›ìê°€ ì¶”ê°€ë¡œ ë„£ê³  ì‹¶ì€ ì •ë³´ë“¤ì„ ì…ë ¥í•´ì£¼ì„¸ìš”
    """
    )

    # radio for upload or copy paste option         
    res_format = st.radio(
        "ì´ë ¥ì„œ ì—…ë¡œë“œ í˜¹ì€ í…ìŠ¤íŠ¸ë¡œ ë¶™ì—¬ë„£ê¸°",
        ('Upload', 'Paste'))

    if res_format == 'Upload':
        # upload_resume
        res_file = st.file_uploader('ğŸ“ pdf í˜•ì‹ ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”!')
        if res_file:
            pdf_reader = PdfReader(res_file)

            # Collect text from pdf
            res_text = ""
            for page in pdf_reader.pages:
                res_text += page.extract_text()
    else:
        # use the pasted contents instead
        res_text = st.text_input('Pasted resume elements')

    with st.form('input_form'):
        # other inputs
        job_desc = st.text_input('ì§ë¬´ ì†Œê°œì„œ')
        user_name = st.text_input('ì§€ì›ì ì´ë¦„')
        company = st.text_input('íšŒì‚¬ ì´ë¦„')
        # manager = st.text_input('Hiring manager')
        question1 = st.text_input('ìê¸°ì†Œê°œì„œ ë¬¸í•­ 1')
        question2 = st.text_input('ìê¸°ì†Œê°œì„œ ë¬¸í•­ 2')
        question3 = st.text_input('ìê¸°ì†Œê°œì„œ ë¬¸í•­ 3')
        ai_temp = st.number_input('AI Temperature (0.0-1.0) Input how creative the API can be',value=.99)

        # submit button
        submitted = st.form_submit_button("ìê¸°ì†Œê°œì„œ ìƒì„±í•˜ê¸°")

    # if the form is submitted run the openai completion   
    if submitted:
        
        template = ChatPromptTemplate.from_messages(
        [
            SystemMessage(
                content=(
                    f"""
                    Write me the resume for {company} in Korean.
                    My resume text: {res_text},
                    
                    There are 3 questions for the resume that you should answer.
                    1. {question1}, in just one paragraph
                    2. {question2}, in just one paragraph
                    3. {question3}, in just one paragraph
                    
                    - Tone : Humble
                    - Style : MECE, accurate
                    - Reader level : New employee
                    - Perspective : Recruiter
                    - Format : markdown
                    
                    You MUST answer in Korean. 
                    """
                )
            ),
            HumanMessagePromptTemplate.from_template("{text}"),
        ])

        llm = ChatOpenAI(model="gpt-3.5-turbo-16k")

        answer = llm(template.format_messages(text=text)).content

        # note that the ChatCompletion is used as it was found to be more effective to produce good results
        # using just Completion often resulted in exceeding token limits
        # according to https://platform.openai.com/docs/models/gpt-3-5
        # Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat 
        # but works well for traditional completions tasks as well.

        # completion = ai.ChatCompletion.create(
        #   #model="gpt-3.5-turbo-16k", 
        #   model = "gpt-3.5-turbo",
        #   temperature=ai_temp,
        #   messages = [
        #     {"role": "user", "content" : f"You will need to generate a cover letter based on specific resume and a job description"},
        #     {"role": "user", "content" : f"My resume text: {res_text}"},
        #     {"role": "user", "content" : f"The job description is: {job_desc}"},
        #     {"role": "user", "content" : f"The candidate's name to include on the cover letter: {user_name}"},
        #     {"role": "user", "content" : f"The job title/role : {role}"},
        #     # {"role": "user", "content" : f"The hiring manager is: {manager}"},
        #     {"role": "user", "content" : f"How you heard about the opportunity: {referral}"},
        #     {"role": "user", "content" : f"The company to which you are generating the cover letter for: {company}"},
        #     {"role": "user", "content" : f"The cover letter should have three content paragraphs"},
        #     {"role": "user", "content" : f""" 
        #     In the first paragraph focus on the following: you will convey who you are, what position you are interested in, and where you heard
        #     about it, and summarize what you have to offer based on the above resume
        #     """},
        #         {"role": "user", "content" : f""" 
        #     In the second paragraph focus on why the candidate is a great fit drawing parallels between the experience included in the resume 
        #     and the qualifications on the job description.
        #     """},
        #             {"role": "user", "content" : f""" 
        #     In the 3RD PARAGRAPH: Conclusion
        #     Restate your interest in the organization and/or job and summarize what you have to offer and thank the reader for their time and consideration.
        #     """},
        #     {"role": "user", "content" : f""" 
        #     note that contact information may be found in the included resume text and use and/or summarize specific resume context for the letter
        #         """},
        #     {"role": "user", "content" : f"Use {user_name} as the candidate"},
            
        #     {"role": "user", "content" : f"Generate a specific cover letter based on the above. Generate the response and include appropriate spacing between the paragraph text"},
            
        #     {"role": "user", "content" : f"You must write down this cover letter in Korean. "},

        #   ]
        # )

        # response_out = completion['choices'][0]['message']['content']
        
        
        st.write(answer)

        # include an option to download a txt file
        st.download_button('Download the cover_letter', answer)